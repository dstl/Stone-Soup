{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e4dc4c-0325-426f-a85a-ceb5bc0c6c15",
   "metadata": {},
   "source": [
    "Consider the scenario where the target evolves according to the Langevin model, driven by a normal sigma-mean mixture with the mixing distribution being the $\\alpha$-stable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f3a32a-bd28-4847-9bc9-46c810cef76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a277e3e-e853-4f90-b431-a5a13b380f48",
   "metadata": {},
   "source": [
    "The state of the target can be represented as 2D Cartesian coordinates, $\\left[x, \\dot x, y, \\dot y\\right]^{\\top}$, modelling both its position and velocity. A simple truth path is created with a sampling rate of 1 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a3940b-6e0c-4c2f-bd8a-4844802e0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.models.transition.driver import AlphaStableNSMDriver\n",
    "from stonesoup.models.transition.driven import Langevin\n",
    "from stonesoup.models.transition.base import CombinedLinearDrivenTransitionModel\n",
    "\n",
    "# And the clock starts\n",
    "start_time = datetime.now().replace(microsecond=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69026f8d-bb9e-4673-b177-45d12cbed859",
   "metadata": {},
   "source": [
    "The `Langevin` class creates a one-dimensional Langevin model, driven by the $\\alpha$-stable NSM mixture process defined in the `AlphaStableNSMDriver` class.\n",
    "\n",
    "\\begin{equation}\n",
    "d \\dot{x}(t)=-\\theta \\dot{x}(t) d t+d W(t), \\quad \\theta>0\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta$, the input parameter to `Langevin`, is the damping factor and $W(t)$ is the non-Gaussian driving process.\n",
    "\n",
    "The noise samples $\\mathbf{w}_n$ are drawn from the $\\alpha$-stable distribution parameterized by the $\\alpha$-stable law, $S_{\\alpha}(\\sigma, \\beta, \\mu)$.\n",
    "\n",
    "The input parameters to `AlphaStableNSMDriver` class are the stability index $\\alpha$, expected jumps per unit time $c$, conditional Gaussian mean $\\mu_W$ & variance $\\sigma_W^2$, and the type of residuals used for the truncated shot-noise representation, specified by `noise_case`. \n",
    "\n",
    "Without diving into technical details, the scaling factor $\\sigma$, skewness parameter $\\beta$ and location $\\mu$, in the $\\alpha$-stable law is a function of the conditional Gaussian parameters $\\mu_W, \\sigma_W^2$. In general, set $\\mu_W=0$ for a symmetric target distribution $\\beta=0$, or $\\mu_W \\neq 0$ to model biased trajectories otherwise. In addition, the size of the resulting trajectories (and jumps) can be adjusted by varying $\\sigma_W^2$.\n",
    "\n",
    "The available noise cases are:\n",
    "\n",
    "1. No residuals, least expensive but drawn noise samples deviate further from target distribution.\n",
    "2. Gaussian approximated residuals, the most expensive but drawn noise samples closest target distribution.\n",
    "3. Partial Gaussian approximated residuals, a compromise between both cases (1) and (2).\n",
    "\n",
    "\n",
    "For interested readers, refer to [1, 2] for more details.\n",
    "\n",
    "Here, we initialise an $\\alpha$-stable driver with the default parameters `mu_W=0, sigma_W2=1, alpha=1.4, noise_case=2, c=10`.\n",
    "\n",
    "Then, the driver instance is injected into the Langevin model for every coordinate axes (i.e., x and y) during initialisation with parameter `theta=0.15`.\n",
    "\n",
    "Note that we overwrite the default `mu_W` parameter in the $\\alpha$-stable driver for the x-coordinate axes to bias our trajectories towards the left. This can be done by passing an additional argument `mu_W = -0.02` when injecting the driver into the Langevin model.\n",
    "\n",
    "Finallt, the `CombinedLinearDrivenTransitionModel` class takes a set of 1-D models and combines them into a linear transition model of arbitrary dimension, $D$, (in this case, $D=2$).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- and  in the $\\alpha$-stable law is a function of the conditional Gaussian mean $\\mu_W$\n",
    "\n",
    "where $\\beta=\\begin{cases} 1, \\quad \\mu_W \\neq 0 \\\\ 0, \\quad \\text{otherwise} \\end{cases}$ with $\\beta=0$ being the a symmetric stable distribution.\n",
    "\n",
    "$\\sigma=\\frac{\\mathbb{E}|w|^\\alpha \\Gamma(2-\\alpha) \\cos(\\pi \\alpha / 2))}{1- \\alpha}$ represent the scale parameter and $\\beta=$ controlling the skewness of the stable distribution. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5fd30c-e869-47e6-9cb5-8907df8b1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 16 # Random seem for reproducibility\n",
    "\n",
    "# Driving process parameters\n",
    "mu_W = 0\n",
    "sigma_W2 = 1\n",
    "alpha = 1.4\n",
    "noise_case=2\n",
    "c=10\n",
    "\n",
    "# Model parameters\n",
    "theta=0.15\n",
    "\n",
    "as_driver_x = AlphaStableNSMDriver(mu_W=mu_W, sigma_W2=sigma_W2, seed=seed, c=c, alpha=alpha, noise_case=noise_case)\n",
    "as_driver_y = as_driver_x # Same driving process in both dimensions and sharing the same latents (jumps)\n",
    "langevin_x = Langevin(cg_driver=as_driver_x, theta=theta, mu_W=-0.02)\n",
    "langevin_y = Langevin(cg_driver=as_driver_y, theta=theta)\n",
    "transition_model = CombinedLinearDrivenTransitionModel([langevin_x, langevin_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a2f4db-995e-42df-995c-0b62be09fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02  0.  ]]\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(transition_model.mu_W)\n",
    "print(transition_model.sigma_W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c85f9-34d1-4d81-bf23-2838f55d0fcf",
   "metadata": {},
   "source": [
    "The ground truth is initialised from (0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d381158e-3147-4b6d-a982-4aa959f4c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [start_time]\n",
    "truth = GroundTruthPath([GroundTruthState([0, 1, 0, 1], timestamp=timesteps[0])])\n",
    "\n",
    "num_steps = 40\n",
    "for k in range(1, num_steps + 1):\n",
    "    timesteps.append(start_time+timedelta(seconds=k))  # add next timestep to list of timesteps\n",
    "    truth.append(GroundTruthState(\n",
    "        transition_model.function(truth[k-1], noise=True, time_interval=timedelta(seconds=1)),\n",
    "        timestamp=timesteps[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6d666-f45d-4344-a2d9-865f599e256b",
   "metadata": {},
   "source": [
    "The simulated ground truth path can be plotted using the in-built plotting classes in Stone Soup.\n",
    "\n",
    "In addition to the ground truth, Stone Soup plotting tools allow measurements and predicted tracks (see later) to be plotted and synced together consistently.\n",
    "\n",
    "An animated plotter that uses Plotly graph objects can be accessed via the `AnimatedPlotterly` class from Stone Soup.\n",
    "\n",
    "Note that the animated plotter requires a list of timesteps as an input, and that `tail_length`\n",
    "is set to 0.3. This means that each data point will be on display for 30% of the total\n",
    "simulation time. The mapping argument is [0, 2] because those are the x and\n",
    "y position indices from our state vector.\n",
    "\n",
    "If a static plotter is preferred, the `Plotterly` class can be used instead\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf6f18f-8586-4511-9603-248ff7f8a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stonesoup.plotter import AnimatedPlotterly\n",
    "# plotter = AnimatedPlotterly(timesteps, tail_length=1.0, width=600, height=600)\n",
    "# plotter.plot_ground_truths(truth, [0, 2])\n",
    "# plotter.fig\n",
    "\n",
    "# Adjust plots if necessary\n",
    "# fig.update_layout(\n",
    "#     legend=dict(\n",
    "#         yanchor=\"bottom\",\n",
    "#         y=0.1,\n",
    "#         xanchor=\"right\",\n",
    "#         x=0.3\n",
    "#     ),\n",
    "#     margin = {'l':0,'t':30,'b':0, 'r': 30},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe8b72f-95e3-423f-aa0d-1470b589634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.plotter import Plotterly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plotter_static = Plotterly(autosize=False,\n",
    "    width=600,\n",
    "    height=600,)\n",
    "plotter_static.plot_ground_truths(truth, [0, 2], marker = {'color' : 'black'})\n",
    "fig = plotter_static.fig\n",
    "fig.write_image(f\"./assets/as_langevin_example_1.pdf\")\n",
    "fig.update_layout(\n",
    "    margin = {'l':30,'t':30,'b':30, 'r': 30},\n",
    "    # showlegend=False,\n",
    "    plot_bgcolor='white',\n",
    "    # font_family=\"Serif\", \n",
    "    font_color='black',\n",
    "      font_size=12,\n",
    "    legend=dict(\n",
    "        yanchor=\"bottom\",\n",
    "        y=0.1,\n",
    "        xanchor=\"right\",\n",
    "        x=0.99\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    # gridcolor='lightgrey'\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    # gridcolor='lightgrey'\n",
    ")\n",
    "fig.write_image(f\"./assets/as_langevin_example_1.pdf\")\n",
    "fig\n",
    "fig.write_image(f\"./assets/as_langevin_example_1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1143d2f-aeaa-44e8-8b01-479a80e0601b",
   "metadata": {},
   "source": [
    "## Simulate measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea94e4b-23fc-465d-ad63-d3417eb708a6",
   "metadata": {},
   "source": [
    "Assume a 'linear' sensor which detects the\n",
    "position, but not velocity, of a target, such that\n",
    "$\\mathbf{z}_k = H_k \\mathbf{x}_k + \\boldsymbol{\\nu}_k$,\n",
    "$\\boldsymbol{\\nu}_k \\sim \\mathcal{N}(0,R)$, with\n",
    "\n",
    "\\begin{align}H_k &= \\begin{bmatrix}\n",
    "                    1 & 0 & 0 & 0\\\\\n",
    "                    0  & 0 & 1 & 0\\\\\n",
    "                      \\end{bmatrix}\\\\\n",
    "          R &= \\begin{bmatrix}\n",
    "                  25 & 0\\\\\n",
    "                    0 & 25\\\\\n",
    "               \\end{bmatrix} \\omega\\end{align}\n",
    "\n",
    "where $\\omega$ is set to 25 initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383f6231-6728-4ff7-b388-581c4284d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0ec57-951a-4ba7-b0fb-a0409f21cb1b",
   "metadata": {},
   "source": [
    "The linear Gaussian measurement model is set up by indicating the number of dimensions in the\n",
    "state vector and the dimensions that are measured (so specifying $H_k$) and the noise\n",
    "covariance matrix $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfe185d-00bc-4fbc-950c-824ba9bdc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,  # Number of state dimensions (position and velocity in 2D)\n",
    "    mapping=(0, 2),  # Mapping measurement vector index to state index\n",
    "    noise_covar=np.array([[16, 0],  # Covariance matrix for Gaussian PDF\n",
    "                          [0, 16]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d2d6b-a6b6-4d9a-8525-764bdfa855cd",
   "metadata": {},
   "source": [
    "The measurements can now be generated and plotted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0346af-dd50-4e2f-b736-1c33baf95326",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = []\n",
    "for state in truth:\n",
    "    measurement = measurement_model.function(state, noise=True)\n",
    "    measurements.append(Detection(measurement,\n",
    "                                  timestamp=state.timestamp,\n",
    "                                  measurement_model=measurement_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c6d788-9db9-42ac-8311-59cb037c05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_static.plot_measurements(measurements, [0, 2], marker = {'color' : 'black'})\n",
    "fig.write_image(f\"./assets/as_langevin_example_2.pdf\")\n",
    "fig\n",
    "fig.write_image(f\"./assets/as_langevin_example_2.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b6cae-87a4-4050-a09c-6f511f9b37b8",
   "metadata": {},
   "source": [
    "## Marginalised Particle Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebcae6-4bdf-42fa-8806-443e2b18e576",
   "metadata": {},
   "source": [
    "The `MarginalisedParticlePredictor` and `MarginalisedParticleUpdater` classes correspond to the predict and update steps\n",
    "respectively.\n",
    "Both require a `TransitionModel` and a `MeasurementModel` instance respectively.\n",
    "To avoid degenerate samples, the `SystematicResampler` is used which is passed to the updater.\n",
    "More resamplers that are included in Stone Soup are covered in the\n",
    "[Resampler Tutorial](https://stonesoup.readthedocs.io/en/latest/auto_tutorials/sampling/ResamplingTutorial.html#sphx-glr-auto-tutorials-sampling-resamplingtutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4284e1f-20e5-4d1f-a5da-06cf0c93a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.predictor.particle import MarginalisedParticlePredictor\n",
    "from stonesoup.resampler.particle import SystematicResampler\n",
    "from stonesoup.updater.particle import MarginalisedParticleUpdater\n",
    "\n",
    "predictor = MarginalisedParticlePredictor(transition_model=transition_model)\n",
    "resampler = SystematicResampler()\n",
    "updater = MarginalisedParticleUpdater(measurement_model, resampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb779115-7823-4bdb-aad1-74d0e076cbdf",
   "metadata": {},
   "source": [
    "To start we create a prior estimate. This is a `MarginalisedParticleState` which describes the state as a distribution of particles.\n",
    "\n",
    "The mean priors are randomly sampled from the standard normal distribution.\n",
    "\n",
    "The covariance priors is initialised with a scalar multiple of the identity matrix ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6edf7062-e0e3-4ab2-8592-31472ad0d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from stonesoup.types.numeric import Probability  # Similar to a float type\n",
    "from stonesoup.types.state import MarginalisedParticleState\n",
    "from stonesoup.types.array import StateVectors\n",
    "\n",
    "number_particles = 1000\n",
    "\n",
    "# Sample from the prior Gaussian distribution\n",
    "states = multivariate_normal.rvs(np.array([0, 1, 0, 1]),\n",
    "                                  np.diag([1., 1., 1., 1.]),\n",
    "                                  size=number_particles)\n",
    "covars = np.stack([np.eye(4) * 100 for i in range(number_particles)], axis=2) # (M, M, N)\n",
    "\n",
    "# Create prior particle state.\n",
    "prior = MarginalisedParticleState(\n",
    "    state_vector=StateVectors(states.T),\n",
    "    covariance=covars,\n",
    "    weight=np.array([Probability(1/number_particles)]*number_particles),\n",
    "                      timestamp=start_time-timedelta(seconds=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fb70b-88a0-4a8d-a0e4-b7911a34be09",
   "metadata": {},
   "source": [
    "We now run the predict and update steps, propagating the collection of particles and resampling at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ac5271-b7b3-44b8-9324-ef1b74d9f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.track import Track\n",
    "\n",
    "track = Track()\n",
    "for measurement in measurements:\n",
    "    prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, measurement)\n",
    "    post = updater.update(hypothesis)\n",
    "    track.append(post)\n",
    "    prior = track[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e76b6-3183-48c7-b7f9-2a27ae860bfa",
   "metadata": {},
   "source": [
    "Plot the resulting track with the sample points at each iteration. Can also change 'plot_history'\n",
    "to True if wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3723a334-818d-4a10-8705-5e0e5a65d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter.plot_tracks(track, [0, 2], particle=True, plot_history=True)\n",
    "# plotter.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c80ec52-8fad-4a33-b182-bc9d5ba2ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_static.plot_tracks(track, [0, 2], particle=False, uncertainty=True, marker = {'opacity' : 0.6, 'color': 'black'})\n",
    "fig.write_image(f\"./assets/as_langevin_example_3.pdf\")\n",
    "fig\n",
    "fig.write_image(f\"./assets/as_langevin_example_3.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9d7c5-6667-49fe-bfc2-81c3ec3b205f",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb55d4-382a-4269-a337-7ff63aba65d6",
   "metadata": {},
   "source": [
    "### Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aced43d-ce76-413f-b6d8-23578f822615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "# times = []\n",
    "# rmse = []\n",
    "# for number_particles in [1000, 500, 100, 50, 10, 2]:\n",
    "#     start = timer()\n",
    "#     # Sample from the prior Gaussian distribution\n",
    "#     states = multivariate_normal.rvs(np.array([0, 1, 0, 1]),\n",
    "#                                       np.diag([1., 1., 1., 1.]),\n",
    "#                                       size=number_particles)\n",
    "#     covars = np.stack([np.eye(4) * 100 for i in range(number_particles)], axis=2) # (M, M, N)\n",
    "    \n",
    "#     # Create prior particle state.\n",
    "#     prior = MarginalisedParticleState(\n",
    "#         state_vector=StateVectors(states.T),\n",
    "#         covariance=covars,\n",
    "#         weight=np.array([Probability(1/number_particles)]*number_particles),\n",
    "#                           timestamp=start_time-timedelta(seconds=1))\n",
    "    \n",
    "#     track = Track()\n",
    "#     for measurement in measurements:\n",
    "#         prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "#         # print(prediction.covariance[..., 0])\n",
    "#         hypothesis = SingleHypothesis(prediction, measurement)\n",
    "#         post = updater.update(hypothesis)\n",
    "#         # print(post.covariance)\n",
    "#         # print(type(post))\n",
    "#         # break\n",
    "#         track.append(post)\n",
    "#         prior = track[-1]\n",
    "\n",
    "#     end = timer()\n",
    "#     times.append((end - start))\n",
    "\n",
    "#     predicted = np.array([t.mean[[0, 2],:] for t in track])\n",
    "#     target = np.array([t.state_vector[[0, 2], :] for t in truth])\n",
    "#     # np.linalg.norm()\n",
    "#     tmp = (target-predicted) ** 2\n",
    "#     # print(tmp.sum().shape)\n",
    "#     # print(np.sqrt(tmp.sum()).shape)\n",
    "#     rmse.append(np.sqrt(tmp.sum()) / len(truth))\n",
    "\n",
    "# print([f\"{t:.4f}\" for t in times]) # in seconds\n",
    "# print([f\"{r:.4f}\" for r in rmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c225b-b4fa-481a-9929-89b6168b454c",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Lemke, Tatjana, and Simon J. Godsill, 'Inference for models with asymmetric α -stable noise processes', in Siem Jan Koopman, and Neil Shephard (eds), Unobserved Components and Time Series Econometrics (Oxford, 2015; online edn, Oxford Academic, 21 Jan. 2016)\n",
    "\n",
    "[2] S. Godsill, M. Riabiz, and I. Kontoyiannis, “The L ́evy state space model,” in 2019 53rd Asilomar Conference on Signals, Systems, and Computers, 2019, pp. 487–494.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c98bb-c731-4dec-8949-b6bce76b6ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
